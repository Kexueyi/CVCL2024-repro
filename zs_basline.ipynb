{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import data_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # 如果使用CUDA\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load CLIP-ViT-L/14\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"clip\"\n",
    "model, preprocess = data_utils.get_model(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(data_utils)\n",
    "dataset_name = \"awa2\"\n",
    "data = data_utils.get_data(dataset_name, preprocess, get_attr=False)\n",
    "dataloader = DataLoader(data, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37322\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antelope', 'grizzly bear', 'killer whale', 'beaver', 'dalmatian', 'persian cat', 'horse', 'german shepherd', 'blue whale', 'siamese cat', 'skunk', 'mole', 'tiger', 'hippopotamus', 'leopard', 'moose', 'spider monkey', 'humpback whale', 'elephant', 'gorilla', 'ox', 'fox', 'sheep', 'seal', 'chimpanzee', 'hamster', 'squirrel', 'rhinoceros', 'rabbit', 'bat', 'giraffe', 'wolf', 'chihuahua', 'rat', 'weasel', 'otter', 'buffalo', 'zebra', 'giant panda', 'deer', 'bobcat', 'pig', 'lion', 'mouse', 'polar bear', 'collie', 'walrus', 'raccoon', 'cow', 'dolphin']\n"
     ]
    }
   ],
   "source": [
    "class_names = data.classes['class_name'].tolist()\n",
    "if dataset_name == \"cub\":\n",
    "    # generalized zero-shot learning\n",
    "    clean_cls = [name.split(\".\")[1] for name in class_names]\n",
    "    #TODO: maybe not that cleaned due to \"_\"\n",
    "    print(clean_cls)\n",
    "elif dataset_name == \"awa2\":\n",
    "    clean_cls = [name.replace(\"+\", \" \") for name in class_names]\n",
    "    print(clean_cls)\n",
    "else:\n",
    "    clean_cls = class_names\n",
    "    print(clean_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import clip\n",
    "\n",
    "def zs_predict(model_name, model, dataloader, class_names, device):\n",
    "    \"\"\"\n",
    "    Set model to eval and evaluate zero-shot classification acc,\n",
    "    return predic labels based on given class_names\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_values = [] # similarity values\n",
    "    all_preds = [] # predicted labels\n",
    "    all_labels = [] # ground truth labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if \"cvcl\" in model_name:\n",
    "            txt_tokens = [model.tokenize(f\"{c}\") for c in class_names]\n",
    "            txt_input  = torch.cat([txt[0] for txt in txt_tokens]).to(device)\n",
    "            txt_len = torch.cat([txt[1] for txt in txt_tokens]).to(device)\n",
    "            txt_feature = model.encode_text(txt_input, txt_len)\n",
    "        \n",
    "        elif \"clip\" in model_name:\n",
    "            txt_input = torch.cat([clip.tokenize(f\"a photo of {c}\") for c in class_names]).to(device)\n",
    "            txt_feature = model.encode_text(txt_input)\n",
    "            \n",
    "        txt_feature /= txt_feature.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        for img, label in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            imgs = img.to(device)\n",
    "            labels = label.to(device)\n",
    "            \n",
    "\n",
    "            #! which is a more arbitrary way\n",
    "            # without considering normalize feature length\n",
    "            # similarity = torch.matmul(image_features, text_features.T)\n",
    "            # preds = similarity.argmax(dim=1)\n",
    "\n",
    "            img_feature = model.encode_image(imgs)\n",
    "            img_feature /= img_feature.norm(dim=-1, keepdim=True)\n",
    "            txt_feature /= txt_feature.norm(dim=-1, keepdim=True)\n",
    "            similarity = (100.0 * img_feature @ txt_feature.T).softmax(dim=-1)\n",
    "            indices = similarity.argmax(dim=-1)\n",
    "            # values, indices = similarity[0].topk(1)\n",
    "\n",
    "            # all_values.extend(values.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(indices.cpu().numpy())\n",
    "            # for index in indices:\n",
    "            #     all_preds.append(class_names[index.item()]) \n",
    "\n",
    "    return all_values, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 73/73 [26:38<00:00, 21.89s/it]\n"
     ]
    }
   ],
   "source": [
    "values, predictions, gt_labels = zs_predict(model_name, model, dataloader, clean_cls, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:100])\n",
    "print(gt_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9400\n",
      "Precision: 0.9328\n",
      "Recall: 0.9226\n",
      "F1 Score: 0.9122\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(gt_labels, predictions)\n",
    "precision = precision_score(gt_labels, predictions, average='macro')\n",
    "recall = recall_score(gt_labels, predictions, average='macro')\n",
    "f1 = f1_score(gt_labels, predictions, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
